{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"preprocess_v2.ipynb","provenance":[{"file_id":"1CyqJCx8VehMhP8zlr8L3N_U_fyWe0QR6","timestamp":1654940045198},{"file_id":"1qLbXZa4Tt9wo5iB07nLm9nIFGpIobKV6","timestamp":1654849992906},{"file_id":"1v1GinF1HkweeG6wRhIZN46kG3KlV-LE1","timestamp":1654749392977}],"collapsed_sections":[],"authorship_tag":"ABX9TyPw+gbIOt87cGI4yV37FYxG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tUu3kvCGfuBT","executionInfo":{"status":"ok","timestamp":1655000756463,"user_tz":-480,"elapsed":21869,"user":{"displayName":"Odelia Tan","userId":"06512993684885144368"}},"outputId":"d85341cb-bd69-40f0-a17b-8d26454579fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["import pandas as pd\n","import datetime\n","from dateutil.relativedelta import relativedelta\n","\n","import ast\n","import string\n","import re\n","\n","import nltk\n","nltk.download('punkt')\n","\n","import numpy as np"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iYEfzd21gkkU","executionInfo":{"status":"ok","timestamp":1655000767005,"user_tz":-480,"elapsed":3008,"user":{"displayName":"Odelia Tan","userId":"06512993684885144368"}},"outputId":"9611a0bf-3c4f-43d0-b6bb-cc6ac7a94658"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"code","source":["def normalize_reviews(filepath, filename):\n","  '''\n","  1. Drop duplicated rows\n","  2. Normalize dates to only the year\n","  3. Normalize ratings to 10\n","  '''\n","  \n","  df = pd.read_excel(filepath)\n","  \n","  # Drop duplicated rows\n","  df.drop_duplicates(keep='first', inplace=True)\n","  \n","  # 1. Normalize dates to only year\n","  \n","  # For Google Review dates\n","  # fix_date_week | fix_date_month | fix_date_year\n","  # Takes current date and minus off respective day, week, month or year\n","  def fix_date_day(day):\n","    date = datetime.datetime.now()\n","    date = date.date()\n","    newdate = date - relativedelta(days=day)\n","    return newdate\n","  \n","  def fix_date_week(week):\n","    date = datetime.datetime.now()\n","    date = date.date()\n","    newdate = date - relativedelta(weeks=week)\n","    return newdate\n","  \n","  def fix_date_month(month):\n","    date = datetime.datetime.now()\n","    date = date.date()\n","    newdate = date - relativedelta(months=month)\n","    return newdate\n","  \n","  def fix_date_year(year):\n","    date = datetime.datetime.now()\n","    date = date.date()\n","    newdate = date - relativedelta(years=year)\n","    return newdate\n","  \n","  # Replace date strings with proper year\n","  # Only up to 10 years\n","  replace_date = {'sehari lalu': fix_date_day(1),\n","                  '2 hari lalu': fix_date_day(2),\n","                  '3 hari lalu': fix_date_day(3),\n","                  '4 hari lalu': fix_date_day(4),\n","                  '5 hari lalu': fix_date_day(5),\n","                  '6 hari lalu': fix_date_day(6),\n","                  'seminggu lalu': fix_date_week(1),\n","                  '2 minggu lalu': fix_date_week(2),\n","                  '3 minggu lalu': fix_date_week(3),\n","                  '4 minggu lalu': fix_date_week(4),\n","                  'sebulan lalu': fix_date_month(1),\n","                  '2 bulan lalu': fix_date_month(2),\n","                  '3 bulan lalu': fix_date_month(3),\n","                  '4 bulan lalu': fix_date_month(4),\n","                  '5 bulan lalu': fix_date_month(5),\n","                  '6 bulan lalu': fix_date_month(6),\n","                  '7 bulan lalu': fix_date_month(7),\n","                  '8 bulan lalu': fix_date_month(8),\n","                  '9 bulan lalu': fix_date_month(9),\n","                  '10 bulan lalu': fix_date_month(10),\n","                  '11 bulan lalu': fix_date_month(11),\n","                  'setahun lalu': fix_date_year(1),\n","                  '2 tahun lalu': fix_date_year(2),\n","                  '3 tahun lalu': fix_date_year(3),\n","                  '4 tahun lalu': fix_date_year(4),\n","                  '5 tahun lalu': fix_date_year(5),\n","                  '6 tahun lalu': fix_date_year(6),\n","                  '7 tahun lalu': fix_date_year(7),\n","                  '8 tahun lalu': fix_date_year(8),\n","                  '9 tahun lalu': fix_date_year(9),\n","                  '10 tahun lalu': fix_date_year(10),}\n","\n","  \n","  # Google review mask\n","  dfg = df[(df['source']=='google_reviews')].copy()\n","  dfg = dfg.replace({\"date\": replace_date})\n","  dfg['date'] = pd.DatetimeIndex(dfg['date']).year\n","  \n","  # Other websites\n","  # Create mask for non-google rows\n","  ngmask = (df['source'] != 'google_reviews')\n","\n","  # Dataframe for non-google rows\n","  df_ng = df[ngmask]\n","\n","  # Get proper date rows from non-google df to separate dataframe\n","  df_ng_prop = df_ng[df_ng['date'].apply(lambda x: isinstance(x, datetime.date))].copy()\n","\n","  # Extract only year from proper date rows\n","  df_ng_prop['date'] = pd.DatetimeIndex(df_ng_prop['date']).year\n","\n","  # Get improper date rows from non-google df to separate dataframe\n","  df_ng_improp = df_ng[df_ng['date'].apply(lambda x: not isinstance(x, datetime.date))].copy()\n","\n","  # Convert datatype to string and only extract last 4 index for year\n","  df_ng_improp['date'] = df_ng_improp['date'].astype(str).str[-4:]\n","\n","  # Rejoin all dataframes\n","  df = pd.concat([dfg, df_ng_prop, df_ng_improp], ignore_index=True)\n","  df['date'] = df['date'].astype(int)\n","  \n","  #2. Normalize ratings to 10\n","  \n","  # Normalize klook ratings\n","  replace_rating = {4:8,\n","                    'Baik': 8,\n","                    'Sangat Direkomendasikan': 10}\n","  df[(df['source'] == 'klook')] = df.replace({'rating': replace_rating})\n","  \n","  # Normalize TripAdvisor ratings\n","  ta_mask = (df['source'] == 'tripadvisor')\n","  # Retrieve index 0 string of rating and multiply by 2\n","  df.loc[ta_mask, 'rating'] = (df.loc[ta_mask, 'rating'].str[0].astype(int))*2\n","  \n","  # Normalize Google Review ratings\n","    # Mask for Google Review ratings\n","  g_mask = (df['source'] == 'google_reviews')\n","  # Retrieve index 14 string of rating and multiply by 2\n","  df.loc[g_mask, 'rating'] = (df.loc[g_mask, 'rating'].str[14].astype(int))*2\n","  \n","  return df"],"metadata":{"id":"MVfBbUVbf7AY","executionInfo":{"status":"ok","timestamp":1655000799698,"user_tz":-480,"elapsed":314,"user":{"displayName":"Odelia Tan","userId":"06512993684885144368"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Enter input filepath\n","df = normalize_reviews(\"/content/gdrive/MyDrive/data/raw/attractions_master.xlsx\", \"attractions_master.xlsx\")\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"id":"VzdYN24JgRFq","executionInfo":{"status":"ok","timestamp":1655000806717,"user_tz":-480,"elapsed":2082,"user":{"displayName":"Odelia Tan","userId":"06512993684885144368"}},"outputId":"810f113f-231b-453e-815c-33f6fd082531"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                        user  date rating  \\\n","0           desuka Panjaitan  2021     10   \n","1      Riska Septi Damayanti  2021     10   \n","2  Mochamad Naufal Irfansyah  2021     10   \n","3                      T1y25  2022     10   \n","4               Rengga Utami  2021     10   \n","\n","                                              review  \\\n","0  Belum Pernah Masuk kedalam, hanya diluar saja....   \n","1  Sumpahh kalo ke Singapore wajib banget ke sini...   \n","2  Seru bisa jajan coklat enak dan murah, kalo ma...   \n","3   Luas banget,banyak spot fotonya,wahananya keren²   \n","4  Wahana Sangat Lengkap ₩Pokoknya Tempatnya Luar...   \n","\n","                                            page_url date_scraped  \\\n","0  https://www.google.com/search?q=universal+stud...   2022-04-27   \n","1  https://www.google.com/search?q=universal+stud...   2022-04-27   \n","2  https://www.google.com/search?q=universal+stud...   2022-04-27   \n","3  https://www.google.com/search?q=universal+stud...   2022-04-27   \n","4  https://www.google.com/search?q=universal+stud...   2022-04-27   \n","\n","           source attraction  \n","0  google_reviews        uss  \n","1  google_reviews        uss  \n","2  google_reviews        uss  \n","3  google_reviews        uss  \n","4  google_reviews        uss  "],"text/html":["\n","  <div id=\"df-f3195470-346f-40cf-8a4b-ade3ca657ed7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user</th>\n","      <th>date</th>\n","      <th>rating</th>\n","      <th>review</th>\n","      <th>page_url</th>\n","      <th>date_scraped</th>\n","      <th>source</th>\n","      <th>attraction</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>desuka Panjaitan</td>\n","      <td>2021</td>\n","      <td>10</td>\n","      <td>Belum Pernah Masuk kedalam, hanya diluar saja....</td>\n","      <td>https://www.google.com/search?q=universal+stud...</td>\n","      <td>2022-04-27</td>\n","      <td>google_reviews</td>\n","      <td>uss</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Riska Septi Damayanti</td>\n","      <td>2021</td>\n","      <td>10</td>\n","      <td>Sumpahh kalo ke Singapore wajib banget ke sini...</td>\n","      <td>https://www.google.com/search?q=universal+stud...</td>\n","      <td>2022-04-27</td>\n","      <td>google_reviews</td>\n","      <td>uss</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Mochamad Naufal Irfansyah</td>\n","      <td>2021</td>\n","      <td>10</td>\n","      <td>Seru bisa jajan coklat enak dan murah, kalo ma...</td>\n","      <td>https://www.google.com/search?q=universal+stud...</td>\n","      <td>2022-04-27</td>\n","      <td>google_reviews</td>\n","      <td>uss</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>T1y25</td>\n","      <td>2022</td>\n","      <td>10</td>\n","      <td>Luas banget,banyak spot fotonya,wahananya keren²</td>\n","      <td>https://www.google.com/search?q=universal+stud...</td>\n","      <td>2022-04-27</td>\n","      <td>google_reviews</td>\n","      <td>uss</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Rengga Utami</td>\n","      <td>2021</td>\n","      <td>10</td>\n","      <td>Wahana Sangat Lengkap ₩Pokoknya Tempatnya Luar...</td>\n","      <td>https://www.google.com/search?q=universal+stud...</td>\n","      <td>2022-04-27</td>\n","      <td>google_reviews</td>\n","      <td>uss</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3195470-346f-40cf-8a4b-ade3ca657ed7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f3195470-346f-40cf-8a4b-ade3ca657ed7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f3195470-346f-40cf-8a4b-ade3ca657ed7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["def preprocess_reviews(df):\n","  '''\n","  1. Remove website URLs and non-characters\n","  2. Remove all characters except alphabets, numbers and punctuations\n","  3. Replace the asterisks people use in place of swear words with a empty string ''\n","  4. Remove leftover emojis\n","  5. If uppercase letter exists, add in _ before uppercase letter and replace uppercase letter to lowercase letter\n","  6. Replace slang words\n","  7. Change the character after _ back to uppercase\n","  8. Remove empty rows in case review only contains emojis\n","  9. Drop rows that have reviews from year 2017and earlier\n","  '''\n","  file = open(\"/content/gdrive/MyDrive/data/bahasa_indonesia_slangwords.txt\", \"r\")\n","  contents = file.read()\n","  slangwords = ast.literal_eval(contents)\n","  \n","  def basic_cleaning(text):\n","      text=re.sub(r'https?://www\\.\\S+\\.com','', text) # Remove website URLs and non-characters\n","      text=re.sub(r'[^A-Za-z0-9`~!@#%&-_=;:,<.>/\\.\\+\\*\\?\\^\\$\\(\\)\\[\\]\\{\\}\\|\\\\|\\s]','', text) # Remove all characters except alphabets, numbers and punctuations\n","      text=re.sub(r'\\*+','', text) # Replace the asterisks people use in place of swear words with a empty string ''\n","      return text\n","  \n","  def remove_emoji(text):\n","      emoji_pattern = re.compile(pattern = \"[\"\n","          u\"\\U0001F600-\\U0001F64F\"  # emoticons\n","          u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n","          u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n","          u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n","          u\"\\U00002702-\\U000027B0\"  \n","          u\"\\U000024C2-\\U0001F251\"\n","                           \"]+\", flags = re.UNICODE)\n","      text = emoji_pattern.sub(r'', text)\n","      return text\n","\n","  # df = pd.read_excel(filepath)\n","  \n","  df['review'] = df['review'].apply(lambda x: basic_cleaning(x))\n","  \n","  df['review'] = df['review'].apply(lambda x: remove_emoji(x))\n","\n","  # if uppercase letter exists, add in _ before uppercase letter and replace uppercase letter to lowercase letter \n","  df['review'] = df['review'].apply(lambda x: \"\".join([\"_\" + ch if ch.isupper() else ch for ch in x]))\n","  \n","  df['review'] = df['review'].apply(lambda x: \" \".join(slangwords.get(word, word) for word in nltk.word_tokenize(x.lower())))\n","\n","  # change the character after _ back to uppercase\n","  df[\"review\"] = df[\"review\"].str.replace(r'_(\\w)', lambda m: m.group(1).upper(), regex=True)\n","\n","  # Remove empty rows in case review only contains emojis\n","  df['review'].replace('', np.nan, inplace=True)\n","  df.dropna(subset=['review'], inplace=True)\n","\n","  # drop rows that have reviews from year 2017and earlier\n","  df.drop(df[df['date'] < 2017].index, inplace = True)\n","\n","  df.to_excel('/content/gdrive/MyDrive/data/clean/attractions_reviews_cleaned.xlsx', index=False) "],"metadata":{"id":"ePIl1DjYgzeJ","executionInfo":{"status":"ok","timestamp":1655000810933,"user_tz":-480,"elapsed":482,"user":{"displayName":"Odelia Tan","userId":"06512993684885144368"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["preprocess_reviews(df)"],"metadata":{"id":"HVbYSMhZmudZ","executionInfo":{"status":"ok","timestamp":1655000818492,"user_tz":-480,"elapsed":3629,"user":{"displayName":"Odelia Tan","userId":"06512993684885144368"}}},"execution_count":6,"outputs":[]}]}